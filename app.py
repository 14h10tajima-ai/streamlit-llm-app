import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

load_dotenv() 

if "OPENAI_API_KEY" not in os.environ and "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# --- LLMåˆæœŸåŒ–ã€€---
def _init_llm():
    try:
        return ChatOpenAI(model="gpt-4o-mini", temperature=0)
    
    except TypeError:
        return ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

LLM = _init_llm()

# --- å°‚é–€å®¶ã®æŒ¯ã‚‹èˆã„ ---
EXPERT_SYSTEM_PROMPTS = {
    "ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒï¼ˆITè»¢è·ï¼‰": (
        "ã‚ãªãŸã¯æ€è€ƒã®è¨€èªåŒ–ãŒå¾—æ„ãªãƒ—ãƒ­ã®ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒã§ã™ã€‚"
        "å—è¬›è€…ã®ä¸å®‰ã‚„å‰æã‚’ä¸å¯§ã«ã»ã©ãã€é¸æŠè‚¢ã¨ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ä¸¦ã¹ã€"
        "çŸ­ã„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚æ–­å®šã—ã™ããšã€æ ¹æ‹ ã‚‚æ·»ãˆã‚‹ã“ã¨ã€‚"
    ),
    "é¢æ¥å®˜ï¼ˆæ¡ç”¨äººäº‹ãƒ»è¾›å£ï¼‰ã€": (
        "ã‚ãªãŸã¯ITæ¥­ç•Œã®æ¡ç”¨æ‹…å½“è€…ã§ã™ã€‚å¿œå‹Ÿè€…ã®å¼·ã¿ãƒ»å¼±ã¿ãƒ»æ‡¸å¿µç‚¹ã‚’å®Ÿå‹™ç›®ç·šã§æŒ‡æ‘˜ã—ã€"
        "è©•ä¾¡åŸºæº–ã®è¦³ç‚¹ï¼ˆã‚¹ã‚­ãƒ«é©åˆãƒ»å†ç¾æ€§ãƒ»å”åƒãƒ»å­¦ç¿’æ€§ï¼‰ã§å…·ä½“çš„ã«ã‚³ãƒ¡ãƒ³ãƒˆã—ã€"
        "æ”¹å–„ææ¡ˆã‚’ç«¯çš„ã«ç¤ºã—ã¦ãã ã•ã„ã€‚ã‚ªãƒ–ãƒ©ãƒ¼ãƒˆã¯ä¸è¦ã€ãŸã ã—å»ºè¨­çš„ã«ã€‚"
    ),
}

# --- LLMå‘¼ã³å‡ºã—é–¢æ•° ---
def ask_llm(user_text: str, expert_key: str) -> str:
    """é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ãƒšãƒ«ã‚½ãƒŠã«åˆã‚ã›ã¦ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆ‡æ›¿ãˆã€LLMã®å›ç­”ã‚’è¿”ã™ã€‚"""
    system_prompt = EXPERT_SYSTEM_PROMPTS.get(expert_key, "You are a helpful assistant.")
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_text),
    ]
    result = LLM(messages)
    return result.content

# --- Streamlit UI ---
st.set_page_config(page_title="è»¢è·æ”¯æ´ã‚¢ãƒ—ãƒª\n\nï¼ˆStreamlit Ã— LangChainï¼‰", page_icon="ğŸ§ª", layout="centered")

st.title("è»¢è·æ”¯æ´ã‚¢ãƒ—ãƒª\n\nï¼ˆStreamlit Ã— LangChainï¼‰")

st.markdown("### æ¦‚è¦")
st.write(
    "è»¢è·ã«è©³ã—ã„å°‚é–€å®¶ã‚’é¸ã‚“ã§å›ç­”ã‚’å¾—ã‚‹ãƒŸãƒ‹ã‚¢ãƒ—ãƒª\n\n"
    "ä½¿ã„æ–¹\n\n"
    "â‘  å°‚é–€å®¶ã‚’é¸ã¶  â‘¡ ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›  â‘¢ é€ä¿¡\n\n"
    "â€»ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã¯ .env ã« OPENAI_API_KEY ã‚’ä¿å­˜ã€‚Cloudã¯ Secrets ã«è¨­å®šã€‚\n\n"
)

expert = st.radio(
    "å°‚é–€å®¶ã®ç¨®é¡ï¼ˆæŒ¯ã‚‹èˆã„ï¼‰ã‚’é¸æŠï¼š",
    list(EXPERT_SYSTEM_PROMPTS.keys()),
    horizontal=True,
)

user_text = st.text_area(
    "ç›¸è«‡å†…å®¹ / è³ªå•ã‚’å…¥åŠ›ï¼ˆä¾‹ï¼šè·å‹™çµŒæ­´ã‚’è¦ç´„ã—ã¦ã€è‡ªå·±PRã‚’ä½œã‚ŠãŸã„ï¼‰",
    height=150,
    placeholder="ã“ã“ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›â€¦",
)

col1, col2 = st.columns([1, 3])
with col1:
    submitted = st.button("é€ä¿¡", type="primary")

# é€ä¿¡æ™‚ã®å‡¦ç†
if submitted:
    if not os.environ.get("OPENAI_API_KEY"):
        st.error("OpenAI APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.env ã¾ãŸã¯ Streamlit Secrets ã« OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    elif not user_text.strip():
        st.error("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("LLMãŒè€ƒãˆä¸­â€¦"):
            try:
                answer = ask_llm(user_text.strip(), expert)
                st.success("å›ç­”")
                st.write(answer)
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{e}")

st.divider()
st.markdown(
    "#### æ³¨æ„\n"
    "- APIã‚­ãƒ¼ã¯**çµ¶å¯¾ã«GitHubã¸ã‚³ãƒŸãƒƒãƒˆã—ãªã„**ï¼ˆ.envã¯.gitignoreå¯¾è±¡ï¼‰ã€‚\n"
    "- æœ¬ç•ªï¼ˆStreamlit Community Cloudï¼‰ã§ã¯ **Secrets** ã« `OPENAI_API_KEY` ã‚’è¨­å®šã€‚\n"
    "- ã“ã®ã‚¢ãƒ—ãƒªã¯å­¦ç¿’ç”¨é€”ã€‚é‡è¦åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§ã€‚"
)